#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
@Time   : 2025/11/11 20:37
@Author : YangFei
@File   : cn_clip.py
@Desc   : Chinese-CLIP å¤šæ¨¡æ€å‘é‡æ¨¡å‹
"""
import os
import logging
import torch
from typing import List, Optional
from functools import lru_cache
from torchvision.transforms import Compose
from cn_clip.clip import load_from_name, tokenize
from cn_clip.clip.model import CLIP


from core.exceptions import BasRequestException

logger = logging.getLogger(__name__)


class ChineseCLIP:
    """Chinese-CLIP å¤šæ¨¡æ€å‘é‡æ¨¡å‹"""

    def __init__(self):
        """åˆå§‹åŒ– Chinese-CLIP æ¨¡å‹å®ä¾‹"""
        self._model: Optional[CLIP] = None
        self._preprocess: Optional[Compose] = None
        # å½“å‰çš„æ¨¡å‹name
        self._model_type: str = ''
        # é¢„å®šä¹‰æ¨¡å‹é…ç½®
        self._model_configs = {
            "mini": "RN50",  # è¿·ä½ ç‰ˆ, é€Ÿåº¦æœ€å¿«ï¼Œé€‚ç”¨äºå¼€å‘æµ‹è¯•åœºæ™¯
            "base": "ViT-B-16",  # åŸºç¡€ç‰ˆ, æ€§èƒ½å‡è¡¡ï¼Œé€‚ç”¨äºå¤§å¤šæ•°åœºæ™¯
            "large": "ViT-L-14",  # æ ‡å‡†ç‰ˆ, é«˜ç²¾åº¦ï¼Œé€‚ç”¨äºå¯¹ç²¾åº¦è¦æ±‚è¾ƒé«˜çš„åœºæ™¯
            "large-hd": "ViT-L-14-336",  # é«˜æ¸…ç‰ˆ, æ›´é«˜åˆ†è¾¨ç‡ï¼Œé€‚ç”¨äºç»†èŠ‚è¦æ±‚é«˜çš„åœºæ™¯
            "huge": "ViT-H-14"  # æ——èˆ°ç‰ˆ, æœ€é«˜ç²¾åº¦ï¼Œé€‚ç”¨äºæè‡´æ€§èƒ½åœºæ™¯
        }

    async def init(self, model_type: str = "mini", model_dir: str = "models/pretrained_weights"):
        """åˆå§‹åŒ–æœåŠ¡ï¼ŒåŠ è½½æ‰€æœ‰æ¨¡å‹"""
        if self._model is not None:
            logger.warning('Chinese-CLIP æ¨¡å‹å®ä¾‹å·²ç»å®Œæˆåˆå§‹åŒ–ã€‚')
            return

        logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ– Chinese-CLIP æ¨¡å‹å®ä¾‹...")

        # æ ‡å‡†åŒ–æ¨¡å‹é”®
        model_key = model_type.strip().lower()
        # ä¿å­˜æ¨¡å‹ç±»å‹
        self._model_type = model_key

        # éªŒè¯æ¨¡å‹ç±»å‹
        if model_key not in self._model_configs:
            raise BasRequestException(
                f"æŒ‡å®šæ¨¡å‹ {model_type} ä¸å­˜åœ¨ï¼Œå¯é€‰é¡¹: {list(self._model_configs.keys())}")

        # ä½¿ç”¨ç»å¯¹è·¯å¾„
        abs_model_dir = os.path.abspath(model_dir)
        logger.info(f"ğŸ“ æ¨¡å‹ç›®å½•: {abs_model_dir}")

        try:
            # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨ GPU
            device = "cuda" if torch.cuda.is_available() else "cpu"

            # è‡ªåŠ¨ä» model_dir æŸ¥æ‰¾å¯¹åº”çš„ .pt æ–‡ä»¶
            model, preprocess = load_from_name(
                name=self._model_configs[model_key],
                device=device,
                download_root=abs_model_dir
            )

            # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­ dropout ç­‰è®­ç»ƒç›¸å…³å±‚ï¼‰
            model.eval()

            # ä¿å­˜æ¨¡å‹å’Œé¢„å¤„ç†å™¨
            self._model = model
            self._preprocess = preprocess

            logger.info(f"âœ…  æˆåŠŸåŠ è½½çš„æ¨¡å‹ç±»å‹ {model_key} -> {device}")

        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ¨¡å‹ {model_key} å¤±è´¥: {e}")
            raise

    async def switch_model(self, model_type: str = 'mini', model_dir: str = "models/pretrained_weights") -> None:
        """åˆ‡æ¢å½“å‰ä½¿ç”¨çš„æ¨¡å‹"""
        logger.debug(f"ğŸ”„ åˆ‡æ¢ Chinese-CLIP æ¨¡å‹åˆ° {model_type}...")

        # æ ‡å‡†åŒ–æ¨¡å‹é”®
        model_key = model_type.strip().lower()

        if self._model_type and model_key != self._model_type:
            # æ¸…ç†å½“å‰æ¨¡å‹èµ„æº
            await self.shutdown()

            # é‡æ–°åˆå§‹åŒ–æ¨¡å‹
            await self.init(model_type=model_type, model_dir=model_dir)

            logger.info(f"âœ… æˆåŠŸåˆ‡æ¢åˆ° {model_type} æ¨¡å‹ã€‚")
        else:
            logger.debug('å·²ç»æ˜¯æŒ‡å®šæ¨¡å‹ç±»å‹ï¼Œæ— éœ€åˆ‡æ¢ã€‚')

    async def shutdown(self) -> None:
        """å…³é—­æœåŠ¡ï¼Œæ¸…ç†èµ„æº"""
        self._model = None
        self._preprocess = None
        self._model_type = ''

        if torch.cuda.is_available():
            torch.cuda.empty_cache()

        get_clip.cache_clear()

        logger.info("Chinese-CLIP æ¨¡å‹å®ä¾‹èµ„æºå·²æ¸…ç†")

    def get_available_models(self) -> List[str]:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        return list(self._model_configs.keys())

    def tokenize(self, texts: List[str]):
        """æ–‡æœ¬æ ‡è®°åŒ–"""
        # ä½¿ç”¨ cn-clip æä¾›çš„ tokenize å‡½æ•°
        return tokenize(texts)

    @property
    def model(self):
        """è·å–å½“å‰åŠ è½½çš„æ¨¡å‹"""
        if self._model is None:
            raise RuntimeError("Chinese-CLIP æ¨¡å‹å®ä¾‹æœªåˆå§‹åŒ–")
        return self._model

    @property
    def preprocess(self):
        """è·å–å½“å‰æ¨¡å‹çš„é¢„å¤„ç†å™¨"""
        if self._preprocess is None:
            raise RuntimeError("Chinese-CLIP æ¨¡å‹å®ä¾‹æœªåˆå§‹åŒ–")
        return self._preprocess


@lru_cache()
def get_clip() -> ChineseCLIP:
    """è·å– Chinese-CLIP æ¨¡å‹å®ä¾‹"""
    return ChineseCLIP()
